Welcome to yrc's Documentation!
===============================

.. image:: images/logo.png
   :alt: yrc logo
   :align: center
   :width: 50%
   :target: _none

Welcome to the documentation for **yrc**!

**yrc** is a flexible framework for research and development in human-AI coordination, policy learning, and reinforcement learning from human feedback. It provides unified abstractions for environments, policies, and algorithms, making it easy to experiment with new learning methods, design custom benchmarks, and analyze agent behavior.

Whether you're a new user looking for a quick start, or a researcher interested in extending the package with your own algorithms and environments, you'll find everything you need in the sections below.

.. toctree::
   :maxdepth: 2
   :hidden:

   Quickstart <quickstart>
   Core concepts <core_concepts/index>
   Algorithms <algorithms/index>
   Tutorials <tutorials/index>
   API reference <autoapi/index>

Getting Started
---------------

- **If you're new to yrc:** Start with the :doc:`Quickstart <quickstart>` guide to get up and running quickly.
- **Explore core ideas:** The :doc:`Core concepts <core_concepts/index>` section introduces yrc’s fundamental abstractions and design philosophy.
- **Try tutorials:** Visit :doc:`Tutorials <tutorials/index>` for step-by-step examples covering common use cases, from custom environments to new algorithms.
- **See what’s included:** The :doc:`Algorithms <algorithms/index>` page lists the standard algorithms provided in yrc and how to use them.
- **Full API documentation:** Dive into :doc:`API reference <autoapi/index>` for details on classes, methods, and configuration options.

About yrc
---------

- **Open-source** and built for extensibility.
- Designed for both **practitioners** and **researchers** in RL, imitation learning, and human-AI collaboration.
- Actively developed and used in academic and industrial research.

Indices and Tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`

